{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FDA Adverse Events & Recalls Data Scraper\n",
        "\n",
        "This notebook scrapes FDA adverse events and recall data for:\n",
        "- **Drugs**: FAERS (FDA Adverse Event Reporting System)\n",
        "- **Medical Devices**: MDR (Medical Device Reporting) \n",
        "- **Biologics**: FAERS + Recalls\n",
        "- **All Products**: FDA Recall Database\n",
        "\n",
        "## Data Sources:\n",
        "1. **FAERS**: https://fis.fda.gov/content/Exports/faers_xml_YYYYQn.zip\n",
        "2. **FDA Recalls**: https://www.fda.gov/safety/recalls-market-withdrawals-safety-alerts\n",
        "3. **OpenFDA API**: https://open.fda.gov/apis/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinstalling numpy and pandas for compatibility...\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.3.3-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Collecting tzdata>=2022.7\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Collecting six>=1.5\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts f2py and numpy-config are installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.3\n",
            "    Uninstalling pandas-2.3.3:\n",
            "      Successfully uninstalled pandas-2.3.3\n",
            "Successfully installed numpy-2.2.6 pandas-2.3.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n",
            "\n",
            "============================================================\n",
            "IMPORTANT: RESTART YOUR KERNEL NOW!\n",
            "============================================================\n",
            "Go to: Kernel -> Restart Kernel\n",
            "Then run the next cell again.\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"Reinstalling numpy and pandas for compatibility...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"numpy\", \"pandas\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"IMPORTANT: RESTART YOUR KERNEL NOW!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Go to: Kernel -> Restart Kernel\")\n",
        "print(\"Then run the next cell again.\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ pandas and numpy imported successfully\n",
            "✓ requests already installed\n",
            "✓ All imports successful!\n",
            "Output directory: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls\n"
          ]
        }
      ],
      "source": [
        "# Import Data\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Try importing\n",
        "try:\n",
        "    from pathlib import Path\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    print(\"✓ pandas and numpy imported successfully\")\n",
        "except (ValueError, ImportError) as e:\n",
        "    error_msg = str(e)\n",
        "    if \"numpy.dtype\" in error_msg or \"binary incompatibility\" in error_msg.lower():\n",
        "        print(\"=\"*60)\n",
        "        print(\"NUMPY/PANDAS COMPATIBILITY ERROR DETECTED\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\nTo fix this issue:\")\n",
        "        print(\"1. Run this command in a NEW cell:\")\n",
        "        print(\"   !pip install --upgrade --force-reinstall numpy pandas\")\n",
        "        print(\"\\n2. RESTART YOUR KERNEL:\")\n",
        "        print(\"   Kernel -> Restart Kernel (or Kernel -> Restart)\")\n",
        "        print(\"\\n3. Run this cell again\")\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        raise ImportError(\"Please follow the instructions above to fix numpy/pandas compatibility\") from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "# Other imports\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "import zipfile\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Install required packages\n",
        "try:\n",
        "    import requests\n",
        "    print(\"✓ requests already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing requests...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
        "    import requests\n",
        "\n",
        "print(\"✓ All imports successful!\")\n",
        "\n",
        "BASE_DIR = Path(\"/Users/Kay Michnicki/AllCode/FDA Data Scraping\")\n",
        "OUTPUT_DIR = BASE_DIR / \"fda_adverse_events_recalls\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Create subdirectories\n",
        "(OUTPUT_DIR / \"adverse_events\").mkdir(exist_ok=True)\n",
        "(OUTPUT_DIR / \"recalls\").mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FDA Data Scraper initialized!\n",
            "\n",
            "OpenFDA API Documentation: https://open.fda.gov/apis/\n",
            "Note: API has rate limits, so requests are throttled\n"
          ]
        }
      ],
      "source": [
        "# OpenFDA API Helper Functions\n",
        "\n",
        "class FDADataScraper:\n",
        "    \"\"\"Scraper for FDA adverse events and recalls using OpenFDA API\"\"\"\n",
        "    \n",
        "    BASE_URL = \"https://api.fda.gov\"\n",
        "    \n",
        "    def __init__(self, limit=1000):\n",
        "        \"\"\"\n",
        "        Initialize scraper\n",
        "        \n",
        "        Args:\n",
        "            limit: Maximum results per API call (max 1000 per request)\n",
        "        \"\"\"\n",
        "        self.limit = limit\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (compatible; FDA-Research-Bot/1.0)'\n",
        "        })\n",
        "    \n",
        "    def search_adverse_events(self, search_query=\"*\", skip=0, limit=None):\n",
        "        \"\"\"\n",
        "        Search FDA adverse events (FAERS data)\n",
        "        \n",
        "        Args:\n",
        "            search_query: Search query (e.g., \"brand_name:KEYTRUDA\", \"*\" for all)\n",
        "            skip: Number of results to skip (for pagination)\n",
        "            limit: Number of results to return (defaults to self.limit)\n",
        "        \n",
        "        Returns:\n",
        "            List of adverse event records\n",
        "        \"\"\"\n",
        "        if limit is None:\n",
        "            limit = self.limit\n",
        "        \n",
        "        url = f\"{self.BASE_URL}/drug/event.json\"\n",
        "        params = {\n",
        "            'search': search_query,\n",
        "            'limit': min(limit, 1000),  # API max is 1000\n",
        "            'skip': skip\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            return data.get('results', [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching adverse events: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def search_recalls_drugs(self, search_query=\"*\", skip=0, limit=None):\n",
        "        \"\"\"Search drug recalls\"\"\"\n",
        "        if limit is None:\n",
        "            limit = self.limit\n",
        "        \n",
        "        url = f\"{self.BASE_URL}/drug/enforcement.json\"\n",
        "        params = {\n",
        "            'search': search_query,\n",
        "            'limit': min(limit, 1000),\n",
        "            'skip': skip\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            return data.get('results', [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching drug recalls: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def search_recalls_devices(self, search_query=\"*\", skip=0, limit=None):\n",
        "        \"\"\"Search medical device recalls\"\"\"\n",
        "        if limit is None:\n",
        "            limit = self.limit\n",
        "        \n",
        "        url = f\"{self.BASE_URL}/device/enforcement.json\"\n",
        "        params = {\n",
        "            'search': search_query,\n",
        "            'limit': min(limit, 1000),\n",
        "            'skip': skip\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            return data.get('results', [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching device recalls: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def search_device_events(self, search_query=\"*\", skip=0, limit=None):\n",
        "        \"\"\"Search medical device adverse events (MDR data)\"\"\"\n",
        "        if limit is None:\n",
        "            limit = self.limit\n",
        "        \n",
        "        url = f\"{self.BASE_URL}/device/event.json\"\n",
        "        params = {\n",
        "            'search': search_query,\n",
        "            'limit': min(limit, 1000),\n",
        "            'skip': skip\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            return data.get('results', [])\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching device events: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def search_recalls_biologics(self, search_query=\"*\", skip=0, limit=None):\n",
        "        \"\"\"Search biologics recalls (filtered from food/enforcement)\"\"\"\n",
        "        if limit is None:\n",
        "            limit = self.limit\n",
        "        \n",
        "        # Biologics may be in food/enforcement endpoint with specific product codes\n",
        "        url = f\"{self.BASE_URL}/food/enforcement.json\"\n",
        "        params = {\n",
        "            'search': search_query,\n",
        "            'limit': min(limit, 1000),\n",
        "            'skip': skip\n",
        "        }\n",
        "        \n",
        "        try:\n",
        "            response = self.session.get(url, params=params, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            # Filter for biologics-related recalls\n",
        "            results = data.get('results', [])\n",
        "            # Filter by product description containing biologics keywords\n",
        "            biologics_keywords = ['biologic', 'vaccine', 'blood', 'plasma', 'biotechnology']\n",
        "            filtered = [r for r in results if any(kw.lower() in str(r.get('product_description', '')).lower() \n",
        "                                                 for kw in biologics_keywords)]\n",
        "            return filtered\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching biologics recalls: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def get_all_adverse_events_paginated(self, search_query=\"*\", max_results=10000):\n",
        "        \"\"\"Get all adverse events (drugs/biologics) with pagination\"\"\"\n",
        "        all_results = []\n",
        "        skip = 0\n",
        "        batch_size = 1000\n",
        "        \n",
        "        print(f\"Fetching adverse events (max {max_results})...\")\n",
        "        with tqdm(total=min(max_results, 10000)) as pbar:\n",
        "            while len(all_results) < max_results:\n",
        "                batch = self.search_adverse_events(search_query, skip=skip, limit=batch_size)\n",
        "                if not batch:\n",
        "                    break\n",
        "                \n",
        "                all_results.extend(batch)\n",
        "                skip += len(batch)\n",
        "                pbar.update(len(batch))\n",
        "                \n",
        "                if len(batch) < batch_size:  # Last batch\n",
        "                    break\n",
        "                \n",
        "                time.sleep(0.5)  # Rate limiting\n",
        "        \n",
        "        return all_results[:max_results]\n",
        "    \n",
        "    def get_all_device_events_paginated(self, search_query=\"*\", max_results=10000):\n",
        "        \"\"\"Get all device adverse events with pagination\"\"\"\n",
        "        all_results = []\n",
        "        skip = 0\n",
        "        batch_size = 1000\n",
        "        \n",
        "        print(f\"Fetching device events (max {max_results})...\")\n",
        "        with tqdm(total=min(max_results, 10000)) as pbar:\n",
        "            while len(all_results) < max_results:\n",
        "                batch = self.search_device_events(search_query, skip=skip, limit=batch_size)\n",
        "                if not batch:\n",
        "                    break\n",
        "                \n",
        "                all_results.extend(batch)\n",
        "                skip += len(batch)\n",
        "                pbar.update(len(batch))\n",
        "                \n",
        "                if len(batch) < batch_size:  # Last batch\n",
        "                    break\n",
        "                \n",
        "                time.sleep(0.5)  # Rate limiting\n",
        "        \n",
        "        return all_results[:max_results]\n",
        "\n",
        "# Initialize scraper\n",
        "scraper = FDADataScraper(limit=1000)\n",
        "print(\"FDA Data Scraper initialized!\")\n",
        "print(\"\\nOpenFDA API Documentation: https://open.fda.gov/apis/\")\n",
        "print(\"Note: API has rate limits, so requests are throttled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processing Functions for Device and Biologics Events\n",
        "\n",
        "def process_device_event_record(record):\n",
        "    \"\"\"Process a medical device adverse event record\"\"\"\n",
        "    try:\n",
        "        device = record.get('device', [{}])[0] if record.get('device') else {}\n",
        "        manufacturer = record.get('manufacturer_d_name', '') or record.get('manufacturer_name', '')\n",
        "        product_code = device.get('device_product_code', '') or record.get('device_product_code', '')\n",
        "        device_name = device.get('device_name', '') or device.get('device_operator_name', '') or record.get('device_name', '')\n",
        "        \n",
        "        processed = {\n",
        "            'event_key': record.get('event_key', ''),\n",
        "            'report_date': record.get('date_of_event', '') or record.get('date_received', ''),\n",
        "            'device_name': device_name,\n",
        "            'device_product_code': product_code,\n",
        "            'manufacturer': manufacturer,\n",
        "            'event_type': record.get('event_type', ''),\n",
        "            'adverse_event_flag': record.get('adverse_event_flag', ''),\n",
        "            'product_problem_flag': record.get('product_problem_flag', ''),\n",
        "            'device_problem': record.get('device_problem', '') or record.get('event_description', ''),\n",
        "            'mdr_text': record.get('mdr_text', ''),\n",
        "            'raw_data': json.dumps(record)\n",
        "        }\n",
        "        return processed\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing device record: {e}\")\n",
        "        return None\n",
        "\n",
        "def process_biologics_event_record(record):\n",
        "    \"\"\"Process a biologics adverse event record (from FAERS, filtered for biologics)\"\"\"\n",
        "    try:\n",
        "        # Similar structure to drug adverse events but flagged as biologics\n",
        "        patient = record.get('patient', {})\n",
        "        drug = record.get('patient', {}).get('drug', [{}])[0] if record.get('patient', {}).get('drug') else {}\n",
        "        reaction = record.get('patient', {}).get('reaction', [])\n",
        "        \n",
        "        # Check if it's a biologic (vaccines, blood products, etc.)\n",
        "        product_name = drug.get('medicinalproduct', '') or ''\n",
        "        is_biologic = any(keyword in product_name.lower() \n",
        "                         for keyword in ['vaccine', 'serum', 'plasma', 'blood', 'biologic', 'biotechnology'])\n",
        "        \n",
        "        processed = {\n",
        "            'safetyreportid': record.get('safetyreportid', ''),\n",
        "            'receivedate': record.get('receivedate', ''),\n",
        "            'serious': record.get('serious', ''),\n",
        "            'product_name': product_name,\n",
        "            'generic_name': drug.get('activesubstancename', ''),\n",
        "            'brand_name': drug.get('openfda', {}).get('brand_name', [''])[0] if drug.get('openfda') else '',\n",
        "            'adverse_reactions': ', '.join([r.get('reactionmeddrapt', '') for r in reaction]) if reaction else '',\n",
        "            'reaction_count': len(reaction) if reaction else 0,\n",
        "            'patient_age': patient.get('patientonsetage', ''),\n",
        "            'patient_sex': patient.get('patientsex', ''),\n",
        "            'is_biologic': is_biologic,\n",
        "            'raw_data': json.dumps(record)\n",
        "        }\n",
        "        return processed if is_biologic else None  # Only return if confirmed biologic\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing biologics record: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FETCHING MEDICAL DEVICE ADVERSE EVENTS\n",
            "============================================================\n",
            "Fetching device adverse events (MDR data)...\n",
            "Note: Start with a sample to test, then scale up\n",
            "Fetching device events (max 1000)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 265.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fetched 1000 device event records\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing device events: 100%|██████████| 1000/1000 [00:00<00:00, 28645.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed 1000 device events\n",
            "\n",
            "Sample data:\n",
            "  device_name manufacturer          event_type device_problem\n",
            "0                                       Injury               \n",
            "1                                       Injury               \n",
            "2                           No answer provided               \n",
            "3                                       Injury               \n",
            "4                                  Malfunction               \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Fetch Medical Device Adverse Events (MDR)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FETCHING MEDICAL DEVICE ADVERSE EVENTS\")\n",
        "print(\"=\"*60)\n",
        "print(\"Fetching device adverse events (MDR data)...\")\n",
        "print(\"Note: Start with a sample to test, then scale up\")\n",
        "\n",
        "# Get device adverse events\n",
        "device_events_raw = scraper.get_all_device_events_paginated(search_query=\"*\", max_results=1000)\n",
        "\n",
        "print(f\"\\nFetched {len(device_events_raw)} device event records\")\n",
        "\n",
        "if device_events_raw:\n",
        "    # Process records\n",
        "    processed_device_events = []\n",
        "    for record in tqdm(device_events_raw, desc=\"Processing device events\"):\n",
        "        processed = process_device_event_record(record)\n",
        "        if processed:\n",
        "            processed_device_events.append(processed)\n",
        "    \n",
        "    device_events_df = pd.DataFrame(processed_device_events)\n",
        "    print(f\"\\nProcessed {len(device_events_df)} device events\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    available_cols = [col for col in ['device_name', 'manufacturer', 'event_type', 'device_problem'] \n",
        "                     if col in device_events_df.columns]\n",
        "    print(device_events_df[available_cols].head() if available_cols else device_events_df.head())\n",
        "else:\n",
        "    device_events_df = None\n",
        "    print(\"No device events data retrieved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FETCHING BIOLOGICS ADVERSE EVENTS\n",
            "============================================================\n",
            "Fetching biologics adverse events from FAERS...\n",
            "Note: Filtering FAERS data for biologics products (vaccines, blood products, etc.)\n",
            "Fetching FAERS data (this may take a while)...\n",
            "Fetching adverse events (max 2000)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:06<00:00, 306.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fetched 2000 total adverse event records\n",
            "Filtering for biologics products...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing biologics events: 100%|██████████| 2000/2000 [00:00<00:00, 10890.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No biologics events found in sample\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Fetch Biologics Adverse Events (from FAERS, filtered)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FETCHING BIOLOGICS ADVERSE EVENTS\")\n",
        "print(\"=\"*60)\n",
        "print(\"Fetching biologics adverse events from FAERS...\")\n",
        "print(\"Note: Filtering FAERS data for biologics products (vaccines, blood products, etc.)\")\n",
        "\n",
        "# Get adverse events and filter for biologics\n",
        "print(\"Fetching FAERS data (this may take a while)...\")\n",
        "all_adverse_events = scraper.get_all_adverse_events_paginated(search_query=\"*\", max_results=2000)\n",
        "\n",
        "print(f\"\\nFetched {len(all_adverse_events)} total adverse event records\")\n",
        "print(\"Filtering for biologics products...\")\n",
        "\n",
        "# Process and filter for biologics\n",
        "processed_biologics_events = []\n",
        "for record in tqdm(all_adverse_events, desc=\"Processing biologics events\"):\n",
        "    processed = process_biologics_event_record(record)\n",
        "    if processed:  # Only biologics are returned\n",
        "        processed_biologics_events.append(processed)\n",
        "\n",
        "if processed_biologics_events:\n",
        "    biologics_events_df = pd.DataFrame(processed_biologics_events)\n",
        "    print(f\"\\nProcessed {len(biologics_events_df)} biologics adverse events\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    available_cols = [col for col in ['product_name', 'brand_name', 'adverse_reactions', 'serious'] \n",
        "                     if col in biologics_events_df.columns]\n",
        "    print(biologics_events_df[available_cols].head() if available_cols else biologics_events_df.head())\n",
        "else:\n",
        "    biologics_events_df = None\n",
        "    print(\"No biologics events found in sample\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching recent adverse events...\n",
            "Note: Start with a small sample to test, then scale up\n",
            "Fetching adverse events (max 1000)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:03<00:00, 290.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fetched 1000 adverse event records\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing records: 100%|██████████| 1000/1000 [00:00<00:00, 16305.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed 1000 adverse events\n",
            "\n",
            "Sample data:\n",
            "     drug_product_name                          adverse_reactions serious  \\\n",
            "0        DURAGESIC-100        DRUG ADMINISTRATION ERROR, OVERDOSE       1   \n",
            "1               BONIVA  Vomiting, Diarrhoea, Arthralgia, Headache       1   \n",
            "2            IBUPROFEN                Dyspepsia, Renal impairment       1   \n",
            "3               LYRICA                           Drug ineffective       2   \n",
            "4  DOXYCYCLINE HYCLATE                      Drug hypersensitivity       2   \n",
            "\n",
            "  receivedate  \n",
            "0    20080707  \n",
            "1    20140306  \n",
            "2    20140228  \n",
            "3    20140312  \n",
            "4    20140312  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Fetch Adverse Events Data\n",
        "\n",
        "def process_adverse_event_record(record):\n",
        "    \"\"\"Process a single adverse event record into structured format\"\"\"\n",
        "    try:\n",
        "        # Extract key fields\n",
        "        patient = record.get('patient', {})\n",
        "        drug = record.get('patient', {}).get('drug', [{}])[0] if record.get('patient', {}).get('drug') else {}\n",
        "        reaction = record.get('patient', {}).get('reaction', [])\n",
        "        \n",
        "        processed = {\n",
        "            'safetyreportid': record.get('safetyreportid', ''),\n",
        "            'receivedate': record.get('receivedate', ''),\n",
        "            'serious': record.get('serious', ''),\n",
        "            'seriousnessdeath': record.get('seriousnessdeath', ''),\n",
        "            'seriousnesslifethreatening': record.get('seriousnesslifethreatening', ''),\n",
        "            'seriousnesshospitalization': record.get('seriousnesshospitalization', ''),\n",
        "            'seriousnessdisabling': record.get('seriousnessdisabling', ''),\n",
        "            'drug_product_name': drug.get('medicinalproduct', ''),\n",
        "            'drug_generic_name': drug.get('activesubstancename', ''),\n",
        "            'drug_brand_name': drug.get('openfda', {}).get('brand_name', [''])[0] if drug.get('openfda') else '',\n",
        "            'adverse_reactions': ', '.join([r.get('reactionmeddrapt', '') for r in reaction]) if reaction else '',\n",
        "            'reaction_count': len(reaction) if reaction else 0,\n",
        "            'patient_age': patient.get('patientonsetage', ''),\n",
        "            'patient_age_unit': patient.get('patientonsetageunit', ''),\n",
        "            'patient_sex': patient.get('patientsex', ''),\n",
        "            'outcome': ', '.join(patient.get('reaction', [{}])[0].get('reactionoutcome', [])) if patient.get('reaction') else '',\n",
        "            'raw_data': json.dumps(record)  # Keep raw for reference\n",
        "        }\n",
        "        return processed\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing record: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fetch sample adverse events (adjust max_results as needed)\n",
        "print(\"Fetching recent adverse events...\")\n",
        "print(\"Note: Start with a small sample to test, then scale up\")\n",
        "\n",
        "# Get recent adverse events (last 1000 for testing)\n",
        "adverse_events_raw = scraper.get_all_adverse_events_paginated(search_query=\"*\", max_results=1000)\n",
        "\n",
        "print(f\"\\nFetched {len(adverse_events_raw)} adverse event records\")\n",
        "\n",
        "if adverse_events_raw:\n",
        "    # Process records\n",
        "    processed_events = []\n",
        "    for record in tqdm(adverse_events_raw, desc=\"Processing records\"):\n",
        "        processed = process_adverse_event_record(record)\n",
        "        if processed:\n",
        "            processed_events.append(processed)\n",
        "    \n",
        "    adverse_events_df = pd.DataFrame(processed_events)\n",
        "    print(f\"\\nProcessed {len(adverse_events_df)} adverse events\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(adverse_events_df[['drug_product_name', 'adverse_reactions', 'serious', 'receivedate']].head())\n",
        "else:\n",
        "    adverse_events_df = None\n",
        "    print(\"No adverse events data retrieved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching drug recalls...\n",
            "Fetched 1000 drug recall records\n",
            "\n",
            "Fetching medical device recalls...\n",
            "Fetched 1000 device recall records\n",
            "\n",
            "Processed 2000 total recall records\n",
            "\n",
            "By product type:\n",
            "product_type\n",
            "drug      1000\n",
            "device    1000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample recalls:\n",
            "  product_type                                product_description  \\\n",
            "0         drug  Progesterone 100 mg/mL in Corn Oil Injection, ...   \n",
            "1         drug  Assured Instant Hand Sanitizer Aloe & Moisturi...   \n",
            "2         drug  Dextroamphetamine Saccharate, Amphetamine Aspa...   \n",
            "3         drug  No Drip Nasal Spray, Oxymetazoline HCl 0.05% N...   \n",
            "4         drug  2 mcg/mL Fentanyl Citrate and 0.16% Bupivacain...   \n",
            "\n",
            "                                   reason_for_recall recall_initiation_date  \n",
            "0  Lack of Assurance of Sterility:  A recall of a...               20150903  \n",
            "1  CGMP Deviations: Next Advanced Antibacterial H...               20200730  \n",
            "2  Some bottles may contain mixed strengths of th...               20200522  \n",
            "3  CGMP Deviations: Products were manufactured wi...               20211026  \n",
            "4  Presence of Particulate Matter: API contaminat...               20160505  \n"
          ]
        }
      ],
      "source": [
        "# Fetch Recalls Data\n",
        "\n",
        "def process_recall_record(record, product_type='drug'):\n",
        "    \"\"\"Process a recall record into structured format\"\"\"\n",
        "    try:\n",
        "        processed = {\n",
        "            'recall_number': record.get('recall_number', ''),\n",
        "            'recall_initiation_date': record.get('recall_initiation_date', ''),\n",
        "            'product_description': record.get('product_description', ''),\n",
        "            'reason_for_recall': record.get('reason_for_recall', ''),\n",
        "            'product_type': product_type,\n",
        "            'recalling_firm': record.get('recalling_firm', ''),\n",
        "            'status': record.get('status', ''),\n",
        "            'raw_data': json.dumps(record)\n",
        "        }\n",
        "        return processed\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing recall record: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fetch Drug Recalls\n",
        "print(\"Fetching drug recalls...\")\n",
        "drug_recalls_list = []\n",
        "for skip in range(0, 1000, 1000):  # Get up to 1000 records\n",
        "    batch = scraper.search_recalls_drugs(search_query=\"*\", skip=skip, limit=1000)\n",
        "    if not batch:\n",
        "        break\n",
        "    drug_recalls_list.extend(batch)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(f\"Fetched {len(drug_recalls_list)} drug recall records\")\n",
        "\n",
        "# Fetch Device Recalls\n",
        "print(\"\\nFetching medical device recalls...\")\n",
        "device_recalls_list = []\n",
        "for skip in range(0, 1000, 1000):\n",
        "    batch = scraper.search_recalls_devices(search_query=\"*\", skip=skip, limit=1000)\n",
        "    if not batch:\n",
        "        break\n",
        "    device_recalls_list.extend(batch)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(f\"Fetched {len(device_recalls_list)} device recall records\")\n",
        "\n",
        "# Process recalls\n",
        "all_recalls = []\n",
        "\n",
        "# Process drug recalls\n",
        "for record in drug_recalls_list:\n",
        "    processed = process_recall_record(record, product_type='drug')\n",
        "    if processed:\n",
        "        all_recalls.append(processed)\n",
        "\n",
        "# Process device recalls\n",
        "for record in device_recalls_list:\n",
        "    processed = process_recall_record(record, product_type='device')\n",
        "    if processed:\n",
        "        all_recalls.append(processed)\n",
        "\n",
        "if all_recalls:\n",
        "    recalls_df = pd.DataFrame(all_recalls)\n",
        "    print(f\"\\nProcessed {len(recalls_df)} total recall records\")\n",
        "    print(f\"\\nBy product type:\")\n",
        "    print(recalls_df['product_type'].value_counts())\n",
        "    print(f\"\\nSample recalls:\")\n",
        "    print(recalls_df[['product_type', 'product_description', 'reason_for_recall', 'recall_initiation_date']].head())\n",
        "else:\n",
        "    recalls_df = None\n",
        "    print(\"No recall data retrieved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "SAVING ALL DATA\n",
            "============================================================\n",
            "\n",
            "✓ Saved 1000 DRUG adverse events to:\n",
            "  Parquet: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/adverse_events/drug_adverse_events.parquet\n",
            "  CSV: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/adverse_events/drug_adverse_events.csv\n",
            "  Unique drugs: 268\n",
            "\n",
            "✓ Saved 1000 DEVICE adverse events to:\n",
            "  Parquet: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/adverse_events/device_adverse_events.parquet\n",
            "  CSV: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/adverse_events/device_adverse_events.csv\n",
            "  Unique devices: 1\n",
            "\n",
            "✗ No biologics adverse events data to save\n",
            "\n",
            "✓ Saved 2000 recall records to:\n",
            "  Parquet: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/recalls/recalls.parquet\n",
            "  CSV: /Users/Kay Michnicki/AllCode/FDA Data Scraping/fda_adverse_events_recalls/recalls/recalls.csv\n",
            "\n",
            "Recalls Summary:\n",
            "  Total records: 2000\n",
            "  By product type:\n",
            "product_type\n",
            "drug      1000\n",
            "device    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Organize and Save Data\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SAVING ALL DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save Drug Adverse Events\n",
        "if adverse_events_df is not None and len(adverse_events_df) > 0:\n",
        "    ae_parquet_path = OUTPUT_DIR / \"adverse_events\" / \"drug_adverse_events.parquet\"\n",
        "    ae_csv_path = OUTPUT_DIR / \"adverse_events\" / \"drug_adverse_events.csv\"\n",
        "    \n",
        "    adverse_events_df.to_parquet(ae_parquet_path, index=False)\n",
        "    adverse_events_df.to_csv(ae_csv_path, index=False)\n",
        "    \n",
        "    print(f\"\\n✓ Saved {len(adverse_events_df)} DRUG adverse events to:\")\n",
        "    print(f\"  Parquet: {ae_parquet_path}\")\n",
        "    print(f\"  CSV: {ae_csv_path}\")\n",
        "    print(f\"  Unique drugs: {adverse_events_df['drug_product_name'].nunique()}\")\n",
        "else:\n",
        "    print(\"\\n✗ No drug adverse events data to save\")\n",
        "\n",
        "# Save Device Adverse Events\n",
        "if device_events_df is not None and len(device_events_df) > 0:\n",
        "    device_ae_parquet_path = OUTPUT_DIR / \"adverse_events\" / \"device_adverse_events.parquet\"\n",
        "    device_ae_csv_path = OUTPUT_DIR / \"adverse_events\" / \"device_adverse_events.csv\"\n",
        "    \n",
        "    device_events_df.to_parquet(device_ae_parquet_path, index=False)\n",
        "    device_events_df.to_csv(device_ae_csv_path, index=False)\n",
        "    \n",
        "    print(f\"\\n✓ Saved {len(device_events_df)} DEVICE adverse events to:\")\n",
        "    print(f\"  Parquet: {device_ae_parquet_path}\")\n",
        "    print(f\"  CSV: {device_ae_csv_path}\")\n",
        "    if 'device_name' in device_events_df.columns:\n",
        "        print(f\"  Unique devices: {device_events_df['device_name'].nunique()}\")\n",
        "else:\n",
        "    print(\"\\n✗ No device adverse events data to save\")\n",
        "\n",
        "# Save Biologics Adverse Events\n",
        "if biologics_events_df is not None and len(biologics_events_df) > 0:\n",
        "    bio_ae_parquet_path = OUTPUT_DIR / \"adverse_events\" / \"biologics_adverse_events.parquet\"\n",
        "    bio_ae_csv_path = OUTPUT_DIR / \"adverse_events\" / \"biologics_adverse_events.csv\"\n",
        "    \n",
        "    biologics_events_df.to_parquet(bio_ae_parquet_path, index=False)\n",
        "    biologics_events_df.to_csv(bio_ae_csv_path, index=False)\n",
        "    \n",
        "    print(f\"\\n✓ Saved {len(biologics_events_df)} BIOLOGICS adverse events to:\")\n",
        "    print(f\"  Parquet: {bio_ae_parquet_path}\")\n",
        "    print(f\"  CSV: {bio_ae_csv_path}\")\n",
        "    if 'product_name' in biologics_events_df.columns:\n",
        "        print(f\"  Unique products: {biologics_events_df['product_name'].nunique()}\")\n",
        "else:\n",
        "    print(\"\\n✗ No biologics adverse events data to save\")\n",
        "\n",
        "# Save Recalls\n",
        "if recalls_df is not None and len(recalls_df) > 0:\n",
        "    # Save as Parquet and CSV\n",
        "    recalls_parquet_path = OUTPUT_DIR / \"recalls\" / \"recalls.parquet\"\n",
        "    recalls_csv_path = OUTPUT_DIR / \"recalls\" / \"recalls.csv\"\n",
        "    \n",
        "    recalls_df.to_parquet(recalls_parquet_path, index=False)\n",
        "    recalls_df.to_csv(recalls_csv_path, index=False)\n",
        "    \n",
        "    print(f\"\\n✓ Saved {len(recalls_df)} recall records to:\")\n",
        "    print(f\"  Parquet: {recalls_parquet_path}\")\n",
        "    print(f\"  CSV: {recalls_csv_path}\")\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(f\"\\nRecalls Summary:\")\n",
        "    print(f\"  Total records: {len(recalls_df)}\")\n",
        "    print(f\"  By product type:\")\n",
        "    print(recalls_df['product_type'].value_counts())\n",
        "else:\n",
        "    print(\"\\n✗ No recall data to save\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Advanced search functions ready!\n",
            "\n",
            "Example usage:\n",
            "  keytruda_ae = search_adverse_events_by_drug(\"KEYTRUDA\", max_results=500)\n",
            "  keytruda_recalls = search_recalls_by_product(\"KEYTRUDA\", product_type=\"drug\")\n"
          ]
        }
      ],
      "source": [
        "# Advanced Search Functions\n",
        "\n",
        "def search_adverse_events_by_drug(drug_name, max_results=1000):\n",
        "    \"\"\"Search adverse events for a specific drug\"\"\"\n",
        "    print(f\"Searching adverse events for: {drug_name}\")\n",
        "    \n",
        "    # Try multiple search strategies\n",
        "    search_queries = [\n",
        "        f\"brand_name:{drug_name}\",\n",
        "        f\"generic_name:{drug_name}\",\n",
        "        f\"openfda.brand_name:{drug_name}\",\n",
        "        f\"patient.drug.medicinalproduct:{drug_name}\"\n",
        "    ]\n",
        "    \n",
        "    all_results = []\n",
        "    for query in search_queries:\n",
        "        results = scraper.get_all_adverse_events_paginated(query, max_results=max_results//len(search_queries))\n",
        "        all_results.extend(results)\n",
        "        time.sleep(0.5)\n",
        "    \n",
        "    return all_results[:max_results]\n",
        "\n",
        "def search_recalls_by_product(product_name, product_type='drug', max_results=500):\n",
        "    \"\"\"Search recalls for a specific product\"\"\"\n",
        "    print(f\"Searching {product_type} recalls for: {product_name}\")\n",
        "    \n",
        "    search_query = f\"product_description:{product_name}\"\n",
        "    \n",
        "    recalls = []\n",
        "    if product_type == 'drug':\n",
        "        for skip in range(0, max_results, 1000):\n",
        "            batch = scraper.search_recalls_drugs(search_query, skip=skip, limit=1000)\n",
        "            if not batch:\n",
        "                break\n",
        "            recalls.extend(batch)\n",
        "            time.sleep(0.5)\n",
        "    elif product_type == 'device':\n",
        "        for skip in range(0, max_results, 1000):\n",
        "            batch = scraper.search_recalls_devices(search_query, skip=skip, limit=1000)\n",
        "            if not batch:\n",
        "                break\n",
        "            recalls.extend(batch)\n",
        "            time.sleep(0.5)\n",
        "    \n",
        "    return recalls[:max_results]\n",
        "\n",
        "print(\"Advanced search functions ready!\")\n",
        "print(\"\\nExample usage:\")\n",
        "print('  keytruda_ae = search_adverse_events_by_drug(\"KEYTRUDA\", max_results=500)')\n",
        "print('  keytruda_recalls = search_recalls_by_product(\"KEYTRUDA\", product_type=\"drug\")')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Important Notes\n",
        "\n",
        "### API Rate Limits\n",
        "- OpenFDA API has rate limits (typically 240 requests per minute)\n",
        "- The scraper includes `time.sleep(0.5)` between requests to avoid hitting limits\n",
        "- For higher volume, you may need an API key: https://open.fda.gov/apis/authentication/\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
