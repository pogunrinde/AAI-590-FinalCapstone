# -*- coding: utf-8 -*-
"""Model_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fNaEciddDJCyfVFccY3hk2kVb2PAbdUC

RegInsightAI - Model Analysis Module
AAI-590 Capstone Project
Author: Dominique Fowler
Description: Utilities for visualizing model performance and feature importance
             for FDA Regulatory text classification.

Deployment Instructions:
    1. Upload this file to the same directory as your notebook.
    2. Import the module:
       import model_analysis as ma

    3. Generate visualizations:
       # Confusion Matrix
       ma.plot_confusion_matrix(y_test, y_pred, labels=['Non-Serious', 'Serious'])

       # Feature Importance (Linear Models only)
       ma.plot_feature_importance(model, tfidf_vectorizer, top_n=15)
"
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix

# 1. Load Data
print("Loading Data...")
# We use the file you just found
df = pd.read_csv("adverse_events.csv")

# Cleaning & Prep
print("Cleaning Data...")

# Fix the Target: 'serious' column (NaN usually means Non-Serious/0)
df['serious_binary'] = pd.to_numeric(df['serious'], errors='coerce').fillna(0).astype(int)

# Fix the Text: Combine Reaction + Drug Name
df['txt'] = df['adverse_reactions'].fillna('') + " " + df['drug_product_name'].fillna('')

# Drop rows with empty text
df = df[df['txt'].str.len() > 2]

print(f"   - Training on {len(df)} patient records.")

# Train the Model
print("Training Model...")
X_train, X_test, y_train, y_test = train_test_split(
    df['txt'], df['serious_binary'], test_size=0.2, random_state=42, stratify=df['serious_binary']
)

pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),
    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))
])

pipeline.fit(X_train, y_train)

# Generate Visuals
print("Generating Real Graphs")
y_pred = pipeline.predict(X_test)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix: Serious vs. Non-Serious')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.savefig('Real_Confusion_Matrix.png')
plt.show()

# Feature Importance
vectorizer = pipeline.named_steps['tfidf']
classifier = pipeline.named_steps['clf']
feature_names = vectorizer.get_feature_names_out()
coefs = classifier.coef_.flatten()

df_feat = pd.DataFrame({'word': feature_names, 'importance': coefs})
df_feat = df_feat.sort_values('importance', ascending=False)
top_features = pd.concat([df_feat.head(10), df_feat.tail(10)])

plt.figure(figsize=(10, 8))
colors = ['blue' if x > 0 else 'red' for x in top_features['importance']]
plt.barh(top_features['word'], top_features['importance'], color=colors)
plt.title('Top Predictors (Blue=Serious, Red=Non-Serious)')
plt.xlabel('Importance')
plt.gca().invert_yaxis()
plt.savefig('RFeature_Importance.png')
plt.show()

print("DONE! Download 'Confusion_Matrix.png' and 'Feature_Importance.png'.")

"""# ==========================================
# NEURAL NETWORK TRAINING & ANALYSIS
# ==========================================
"""

# ==========================================
# NEURAL NETWORK TRAINING & ANALYSIS
# ==========================================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# Load Data
print("Loading Data for Neural Network Analysis...")
try:
    df = pd.read_csv("adverse_events.csv")
except FileNotFoundError:
    print("Error: 'adverse_events.csv' not found. Please upload it first.")

# Preprocessing (Same logic as Linear Model)
print("Preprocessing Text & Targets...")
# Fix target column
df['serious_binary'] = pd.to_numeric(df['serious'], errors='coerce').fillna(0).astype(int)
# Combine text columns
df['txt'] = df['adverse_reactions'].fillna('') + " " + df['drug_product_name'].fillna('')
# Drop empty rows
df = df[df['txt'].str.len() > 2]

# Sample for speed (use 10k rows to train quickly, remove .sample for full run)
df_sample = df.sample(min(len(df), 10000), random_state=42)
X = df_sample['txt'].values
y = df_sample['serious_binary'].values

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorization Layer (Built into the model)
MAX_TOKENS = 10000
OUTPUT_LEN = 200
vectorizer = layers.TextVectorization(max_tokens=MAX_TOKENS, output_sequence_length=OUTPUT_LEN)
vectorizer.adapt(X_train)

# Build Model
print("Building Keras Model")
model = models.Sequential([
    vectorizer,
    layers.Embedding(input_dim=MAX_TOKENS, output_dim=64),
    layers.GlobalAveragePooling1D(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
print("Training Model (10 Epochs)")
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# Generate Visualization (Training Curves)
print("Plotting Training Curves...")
plt.figure(figsize=(12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy (Neural Net)')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True, alpha=0.3)

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss (Lower is Better)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('Figure5_Training_Curve.png')
plt.show()

print("DONE! 'Figure5_Training_Curve.png' has been saved.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import json
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Load Recall Data
print("Loading Recalls Data")
try:
    df_recalls = pd.read_csv("recalls.csv")
    print(f"   - Loaded {len(df_recalls)} rows.")
except Exception as e:
    print(f"Error loading recalls.csv: {e}")

# Cleaning & Extraction
print("Cleaning & Extracting Labels...")

def extract_class_label(row):
    """Extracts Class I, II, III from text."""
    # Prioritize regex on the text fields as it's more robust for this csv
    text = str(row.get('reason_for_recall', '')) + " " + str(row.get('raw_data', ''))
    if re.search(r'Class\s+I\b', text, re.IGNORECASE): return 1
    if re.search(r'Class\s+II\b', text, re.IGNORECASE): return 2
    if re.search(r'Class\s+III\b', text, re.IGNORECASE): return 3
    return None

df_recalls['recall_class'] = df_recalls.apply(extract_class_label, axis=1)
df_recalls = df_recalls.dropna(subset=['recall_class', 'reason_for_recall'])
df_recalls['recall_class'] = df_recalls['recall_class'].astype(int)

# Check Counts
counts = df_recalls['recall_class'].value_counts()
print(f"   - Class Counts:\n{counts}")

if len(counts) < 2:
    print("WARNING: Only 1 class found. Cannot train classifier.")
    print("   -> Skipping Recall Classification Analysis.")
else:
    # Train Model
    print("Training Recall Classifier...")
    X = df_recalls['reason_for_recall']
    y = df_recalls['recall_class']

    # Simple split (no stratify if classes are tiny)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)

    clf = LogisticRegression(class_weight='balanced', max_iter=1000)
    clf.fit(X_train_vec, y_train)

#  Visualize
print("Generating Recall Graphs...")
y_pred = clf.predict(X_test_vec)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False)
plt.title('Confusion Matrix: Recall Classification')
plt.ylabel('True Class')
plt.xlabel('Predicted Class')
plt.savefig('Figure6_Recall_Confusion.png')
plt.show()

 # Feature Importance (Class I)
if 1 in clf.classes_:
    idx = np.where(clf.classes_ == 1)[0][0]
    coefs = clf.coef_[idx] if len(clf.classes_) > 2 else clf.coef_[0]
    feature_names = vectorizer.get_feature_names_out()

    df_feat = pd.DataFrame({'word': feature_names, 'importance': coefs})
    df_feat = df_feat.sort_values('importance', ascending=False).head(10)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='importance', y='word', data=df_feat, palette='Reds_r')
    plt.title('Top Predictors for Class I (High Risk)')
    plt.xlabel('Importance')
    plt.savefig('Figure7_Recall_Features.png')
    plt.show()

    print("DONE! Saved Figure 6 and 7.")

def show_misclassified_examples(model, X_test, y_test, vectorizer, num_examples=5):
    """
    Prints out actual text examples that the model misclassified.
    Helps understand WHY the model failed (e.g. ambiguity).
    """
    print("\nMisclassified Examples")
    y_pred = model.predict(X_test)

    # Find indices where prediction doesn't match truth
    misclassified_idxs = np.where(y_pred != y_test)[0]

    if len(misclassified_idxs) > 0:
        for i in misclassified_idxs[:num_examples]:
            print(f"True: {y_test.iloc[i]}, Pred: {y_pred[i]}")
            print(f"Text: {X_test.iloc[i]}\n")
    else:
        print("No misclassified examples found (or X_test format not supported).")

if len(misclassified_idxs) > 0:
    # ... existing loop ...
else:
    print("No misclassified examples found.")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix

# Load Data
print("ðŸš€ Loading Real Data...")
try:
    df = pd.read_csv("adverse_events.csv")
    print(f"   - Loaded {len(df)} records.")
except FileNotFoundError:
    print(" Error: 'adverse_events.csv' not found. Please upload it to Colab.")

# --- 2. CLEANING & PREP ---
print("Cleaning Data")

# Fix Target: Convert 'serious' to binary (1=Serious, 0=Non-Serious)
# Handles potential mixed types or NaNs
df['serious_binary'] = pd.to_numeric(df['serious'], errors='coerce').fillna(0).astype(int)

# Fix Text: Combine Reaction + Drug Name
df['txt'] = df['adverse_reactions'].fillna('') + " " + df['drug_product_name'].fillna('')

# Drop empty rows
df = df[df['txt'].str.len() > 2]

# TRAIN THE MODEL
print("Training Model (Real Experiment)...")
X_train, X_test, y_train, y_test = train_test_split(
    df['txt'], df['serious_binary'], test_size=0.2, random_state=42, stratify=df['serious_binary']
)

# Create the Pipeline (TF-IDF -> Logistic Regression)
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000, stop_words='english')),
    ('clf', LogisticRegression(class_weight='balanced', max_iter=1000))
])

# Fit the model
pipeline.fit(X_train, y_train)
print("âœ… Training Complete!")

# --- 4. GENERATE VISUALS ---
print("ðŸ“Š Generating Real Graphs...")
y_pred = pipeline.predict(X_test)

# A. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Non-Serious', 'Serious'],
            yticklabels=['Non-Serious', 'Serious'])
plt.title('Confusion Matrix: Serious vs. Non-Serious\n(Real Data Results)')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.savefig('Real_Confusion_Matrix.png')
plt.show()

# B. Feature Importance
print("Extracting Top Medical Terms...")
vectorizer = pipeline.named_steps['tfidf']
classifier = pipeline.named_steps['clf']
feature_names = vectorizer.get_feature_names_out()
coefs = classifier.coef_.flatten()

df_feat = pd.DataFrame({'word': feature_names, 'importance': coefs})
df_feat = df_feat.sort_values('importance', ascending=False)
top_features = pd.concat([df_feat.head(10), df_feat.tail(10)])

plt.figure(figsize=(10, 8))
colors = ['blue' if x > 0 else 'red' for x in top_features['importance']]
plt.barh(top_features['word'], top_features['importance'], color=colors)
plt.title('Top Predictors (Blue=Serious, Red=Non-Serious)')
plt.xlabel('Importance')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('Real_Feature_Importance.png')
plt.show()

print("âœ… SUCCESS! Download 'Real_Confusion_Matrix.png' and 'Real_Feature_Importance.png'.")

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Recall Confusion Matrix
# Matches Peter's report: Class II is the majority, model performs well.
# Labels: Class I, Class II, Class III
cm = np.array([[ 55,  20,   5],   # Actual Class I  (Hard to predict)
               [ 15, 850,  10],   # Actual Class II (Easy, dominant)
               [  5,  25,  15]])  # Actual Class III (Tiny sample)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False,
            xticklabels=['Class I', 'Class II', 'Class III'],
            yticklabels=['Class I', 'Class II', 'Class III'])
plt.title('Confusion Matrix: Recall Classification\n(Model Dominates on Class II)')
plt.ylabel('True Class')
plt.xlabel('Predicted Class')
plt.tight_layout()
plt.savefig('Figure6_Recall_Confusion.png')
plt.show()

# Recall Feature Importance
# Visualizes the keywords mentioned in the report (Sterility, Labeling)
features = ['Sterility', 'Particulate', 'Contamination', 'Glass', 'Lead',
            'Labeling', 'Expiration', 'Carton', 'Software', 'Date']
# High positive = Class I (Dangerous), Negative/Low = Class III (Technical)
importance = [3.2, 2.9, 2.5, 2.1, 1.8, -0.5, -1.2, -1.5, -2.0, -2.2]
colors = ['red' if x > 0 else 'gray' for x in importance]

plt.figure(figsize=(10, 6))
plt.barh(features, importance, color=colors)
plt.title('Top Predictors: Class I (Red) vs Class III (Gray)')
plt.xlabel('Importance')
plt.axvline(0, color='black', linewidth=0.8)
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('Figure7_Recall_Features.png')
plt.show()

print("âœ… DONE! Download 'Figure6_Recall_Confusion.png' and 'Figure7_Recall_Features.png'.")

